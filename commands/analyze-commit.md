---
name: analyze-commit
description: Deep analysis of a single commit with context gathering and Notion export
---

# Analyze Single Commit

Perform comprehensive analysis of a single commit, understanding the **Why**, **What**, **Impact**, and **Design** behind the changes.

## Usage

```
/analyze-commit <commit-hash>
/analyze-commit <github-url> <commit-hash>  # URL optional if project registered
```

**Examples**:
```
# After /register-oss - URL not needed!
/analyze-commit abc1234567
/analyze-commit abc1234  # Short hash OK

# Or with explicit URL
/analyze-commit https://github.com/expressjs/express abc1234567
```

## Analysis Workflow

### Phase 0: Repository Setup and Local Clone

**IMPORTANT**: This command requires a local clone of the repository for deep code analysis.

#### Step 0.1: Repository URL Resolution

```python
# If URL not provided, read from memory
if not github_url:
    current_oss = serena_mcp.read_memory("current_oss")

    if not current_oss:
        print("âš ï¸  No repository specified and no current project set")
        print("Please either:")
        print("  1. Register a project: /register-oss <github-url>")
        print("  2. Or specify URL: /analyze-commit <github-url> <commit-hash>")
        return

    github_url = current_oss["repo_url"]
    owner = current_oss["owner"]
    repo = current_oss["repo"]
    notion_oss_page_id = current_oss["notion_page_id"]
    local_repo_path = current_oss.get("local_repo_path")  # May be None

    print(f"ğŸ“¦ Using current project: {owner}/{repo}")
else:
    # URL provided, parse it
    owner, repo = parse_github_url(github_url)
    local_repo_path = None
```

#### Step 0.2: Local Clone Verification

Check if repository is cloned locally:

```python
import os
from pathlib import Path

# Determine expected clone location
if not local_repo_path:
    # Default location: ~/.claude/deep-code-reader/repos/{owner}/{repo}
    home = Path.home()
    local_repo_path = home / ".claude" / "deep-code-reader" / "repos" / owner / repo

# Check if clone exists
if not os.path.exists(local_repo_path / ".git"):
    print(f"âš ï¸  Repository not cloned locally")
    print(f"")
    print(f"This repository needs to be registered first for deep code analysis:")
    print(f"")
    print(f"  /register-oss {github_url}")
    print(f"")
    print(f"The /register-oss command will:")
    print(f"  â€¢ Clone the repository to ~/.claude/deep-code-reader/repos/{owner}/{repo}")
    print(f"  â€¢ Set up Notion database for tracking")
    print(f"  â€¢ Enable deep code analysis features")
    print(f"")
    print(f"After registration, run this command again.")
    return

print(f"âœ… Repository found: {local_repo_path}")

# Activate project in Serena MCP for symbol analysis
serena_mcp.activate_project(str(local_repo_path))
print(f"ğŸ” Serena MCP activated for deep analysis")
```

#### Step 0.3: Checkout Commit

```python
# Checkout the specific commit for analysis
import subprocess

try:
    # Save current branch
    result = subprocess.run(
        ["git", "rev-parse", "--abbrev-ref", "HEAD"],
        cwd=local_repo_path,
        capture_output=True,
        text=True
    )
    original_branch = result.stdout.strip()

    # Checkout the commit
    subprocess.run(
        ["git", "checkout", commit_hash],
        cwd=local_repo_path,
        check=True,
        capture_output=True
    )

    print(f"ğŸ“ Checked out commit: {commit_hash}")

    # Store for cleanup later
    cleanup_info = {
        "repo_path": local_repo_path,
        "original_branch": original_branch,
        "commit_hash": commit_hash
    }

except subprocess.CalledProcessError as e:
    print(f"âŒ Error checking out commit: {e}")
    return
```

### Phase 1: Commit Data Gathering (use GitHub MCP)

Fetch commit information:

```python
# Get commit details
commit_info = github_mcp.get_commit(owner, repo, commit_hash)

Required data:
- Commit hash (full & short)
- Commit message
- Author & date
- Changed files
- Diff content
- Parent commits
```

### Phase 2: Context Gathering (use GitHub MCP + Sequential Thinking)

#### 2.1 Related Issues

Extract issue references from:
- Commit message: `#123`, `fixes #456`, `closes #789`
- PR associations: If commit is part of a PR

```python
# Find related issues
issues = extract_issue_numbers(commit_message)
for issue_num in issues:
    issue_data = github_mcp.get_issue(owner, repo, issue_num)
    # Store: issue title, description, labels
```

#### 2.2 Before & After Context

Get surrounding commits:

```python
# Get commit timeline
before_commits = git log --oneline {commit}~3..{commit}~1
after_commits = git log --oneline {commit}..{commit}+2

Context includes:
- 1-2 commits before
- 1-2 commits after
- Brief description of each
```

#### 2.3 Pull Request Context (if applicable)

```python
# Find associated PR
prs = github_mcp.search_prs(query=f"commit:{commit_hash}")
if prs:
    pr_data = github_mcp.get_pr(owner, repo, pr.number)
    # Store: PR title, description, reviews, comments
```

### Phase 3: Deep Code Analysis (use GitHub MCP + Sequential Thinking + Serena MCP)

**IMPORTANT**: This phase performs **line-by-line code analysis** for deep understanding.

#### 3.1 ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªå†…å®¹å–å¾— (from Local Clone + Serena MCP)

For each changed file, get the full file content from local clone:

```python
# Get commit details from GitHub API
commit_data = github_mcp.get_commit(owner, repo, commit_hash)

files_analysis = []

for file in commit_data["files"]:
    file_path = file["filename"]
    full_path = local_repo_path / file_path

    # Get the FULL file content AFTER the change (currently checked out)
    if file["status"] != "deleted":
        file_content_after = serena_mcp.read_file(
            relative_path=file_path,
            max_answer_chars=-1  # Read entire file
        )
    else:
        file_content_after = None

    # Get the file content BEFORE the change
    if file["status"] != "added":
        # Checkout parent commit temporarily to read old content
        parent_sha = commit_data["parents"][0]["sha"]

        subprocess.run(
            ["git", "checkout", parent_sha, "--", file_path],
            cwd=local_repo_path,
            capture_output=True
        )

        file_content_before = serena_mcp.read_file(
            relative_path=file_path,
            max_answer_chars=-1
        )

        # Restore to current commit
        subprocess.run(
            ["git", "checkout", commit_hash, "--", file_path],
            cwd=local_repo_path,
            capture_output=True
        )
    else:
        file_content_before = None

    # Get the patch/diff from GitHub
    diff = file["patch"]

    # Use Serena MCP to get symbol information
    symbols_info = None
    if is_code_file(file_path) and file["status"] != "deleted":
        try:
            # Get overview of symbols in this file
            symbols_info = serena_mcp.get_symbols_overview(
                relative_path=file_path,
                max_answer_chars=-1
            )
        except Exception as e:
            print(f"âš ï¸  Could not analyze symbols in {file_path}: {e}")

    # Store all for detailed analysis
    files_analysis.append({
        "path": file_path,
        "status": file["status"],  # added, modified, deleted
        "content_after": file_content_after,
        "content_before": file_content_before,
        "diff": diff,
        "additions": file["additions"],
        "deletions": file["deletions"],
        "symbols": symbols_info  # NEW: Symbol-level information
    })

print(f"âœ… Loaded {len(files_analysis)} files for deep analysis")
```

#### 3.2 å¤‰æ›´ã®æ„å›³ (Why)

Analyze **why** this change was made:

```markdown
- å•é¡Œ: What problem does this solve?
- å‹•æ©Ÿ: Why was this approach chosen?
- èƒŒæ™¯: What's the business/technical context?

Sources:
- Commit message
- Related issue descriptions
- PR discussions
- Code comments in changed files
```

#### 3.3 ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®è©³ç´°è§£æ (Detailed File Analysis)

**For EACH changed file**, perform deep analysis:

```python
for file_info in files_analysis:
    file_analysis = {
        "file_path": file_info["path"],
        "file_role": "",  # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²
        "change_summary": "",  # å¤‰æ›´ã®æ¦‚è¦
        "detailed_explanation": "",  # è©³ç´°ãªèª¬æ˜
        "code_walkthrough": []  # ã‚³ãƒ¼ãƒ‰ã®è¡Œã”ã¨ã®è§£èª¬
    }

    # Step 1: ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²ã‚’ç†è§£
    file_analysis["file_role"] = analyze_file_role(
        file_path=file_info["path"],
        content=file_info["content_after"],
        project_context=commit_data
    )

    # Step 2: å¤‰æ›´ã®æ¦‚è¦
    file_analysis["change_summary"] = f"""
    - å¤‰æ›´ã‚¿ã‚¤ãƒ—: {file_info["status"]} ({file_info["additions"]}è¡Œè¿½åŠ , {file_info["deletions"]}è¡Œå‰Šé™¤)
    - ä¸»ãªå¤‰æ›´å†…å®¹: [AIãŒåˆ†æ]
    """

    # Step 3: è©³ç´°ãªè§£èª¬ (LINE-BY-LINE)
    # Parse the diff to identify changed sections
    changed_sections = parse_diff(file_info["diff"])

    for section in changed_sections:
        section_analysis = {
            "line_range": section["line_range"],
            "change_type": section["type"],  # addition, deletion, modification
            "code_before": section["code_before"],
            "code_after": section["code_after"],
            "explanation": ""
        }

        # DEEP ANALYSIS: Explain what this code does LINE BY LINE
        section_analysis["explanation"] = analyze_code_section(
            code=section["code_after"],
            context={
                "file_path": file_info["path"],
                "file_role": file_analysis["file_role"],
                "full_content": file_info["content_after"],
                "change_intent": commit_message
            }
        )

        file_analysis["code_walkthrough"].append(section_analysis)
```

**Example of detailed analysis output**:

```markdown
### ğŸ“„ src/auth/middleware.js

**ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²**:
èªè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’æä¾›ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¤œè¨¼ã™ã‚‹ã€‚å…¨ã¦ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‰ã«å®Ÿè¡Œã•ã‚Œã‚‹ã€‚

**å¤‰æ›´ã®æ¦‚è¦**:
- å¤‰æ›´ã‚¿ã‚¤ãƒ—: modified (45è¡Œè¿½åŠ , 12è¡Œå‰Šé™¤)
- ä¸»ãªå¤‰æ›´: å…¥åŠ›æ¤œè¨¼ã®å¼·åŒ–ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®è¿½åŠ 

---

#### ğŸ” è©³ç´°ãªå¤‰æ›´è§£æ

**ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 1: ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼ã®å¼·åŒ– (L23-L45)**

å¤‰æ›´å‰ã®ã‚³ãƒ¼ãƒ‰:
```javascript
function validateToken(token) {
  return jwt.verify(token, SECRET_KEY);
}
```

å¤‰æ›´å¾Œã®ã‚³ãƒ¼ãƒ‰:
```javascript
function validateToken(token) {
  // L23: ãƒˆãƒ¼ã‚¯ãƒ³ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ - ç©ºæ–‡å­—åˆ—ã‚„nullã‚’é˜²ã
  if (!token || typeof token !== 'string') {
    throw new Error('Invalid token format');
  }

  // L27-28: ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ãƒã‚§ãƒƒã‚¯ - ç•°å¸¸ã«çŸ­ã„/é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ‹’å¦
  // JWTã®æ¨™æº–çš„ãªé•·ã•ã¯200-300æ–‡å­—ç¨‹åº¦
  if (token.length < 50 || token.length > 500) {
    throw new Error('Token length out of acceptable range');
  }

  // L32-36: ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
  // JWTã¯ "header.payload.signature" ã®3éƒ¨æ§‹æˆ
  const parts = token.split('.');
  if (parts.length !== 3) {
    throw new Error('Malformed JWT token');
  }

  // L40-45: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ¤œè¨¼
  // å„ãƒ‘ãƒ¼ãƒˆãŒBase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
  try {
    parts.forEach(part => {
      Buffer.from(part, 'base64');
    });
  } catch (e) {
    throw new Error('Invalid Base64 encoding in token');
  }

  // L45: æœ€çµ‚çš„ãªç½²åæ¤œè¨¼ï¼ˆå…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰
  return jwt.verify(token, SECRET_KEY);
}
```

**ãªãœã“ã®å¤‰æ›´ãŒå¿…è¦ã ã£ãŸã‹**:
CVE-2024-1234ã§å ±å‘Šã•ã‚ŒãŸè„†å¼±æ€§ã«å¯¾å‡¦ã€‚æ”»æ’ƒè€…ãŒä¸æ­£ãªå½¢å¼ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é€ä¿¡ã—ã¦ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã•ã›ã‚‹å•é¡Œã‚’ä¿®æ­£ã€‚

**ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œè©³ç´°**:
1. **L23-25**: ã¾ãšæœ€åˆã«ãƒˆãƒ¼ã‚¯ãƒ³ã®å­˜åœ¨ã¨å‹ã‚’ãƒã‚§ãƒƒã‚¯ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€`undefined`ã‚„æ•°å€¤ãªã©ã®ç„¡åŠ¹ãªå…¥åŠ›ã‚’æ—©æœŸã«ãƒªã‚¸ã‚§ã‚¯ãƒˆã€‚
2. **L27-30**: é•·ã•ãƒã‚§ãƒƒã‚¯ã§ã€æ¥µç«¯ã«çŸ­ã„ï¼ˆç·å½“ãŸã‚Šæ”»æ’ƒï¼‰ã‚„é•·ã„ï¼ˆDoSæ”»æ’ƒï¼‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é˜²ãã€‚
3. **L32-36**: JWTã®åŸºæœ¬æ§‹é€ ï¼ˆ3ãƒ‘ãƒ¼ãƒˆæ§‹æˆï¼‰ã‚’æ¤œè¨¼ã€‚ä¸æ­£ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ—©æœŸæ¤œå‡ºã€‚
4. **L40-44**: å„ãƒ‘ãƒ¼ãƒˆã®Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œè¨¼ã€‚ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã§ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹å‰ã«æ•æ‰ã€‚
5. **L45**: å…¨ã¦ã®æ¤œè¨¼ã‚’é€šéã—ãŸå¾Œã€å…ƒã®`jwt.verify()`ã‚’å®Ÿè¡Œã€‚

**ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³**:
- **Defense in Depth**: è¤‡æ•°å±¤ã®æ¤œè¨¼ã§æ”»æ’ƒã‚’é˜²ã
- **Fail Fast**: å•é¡Œã‚’æ—©æœŸã«æ¤œå‡ºã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
- **Input Validation**: å…¨ã¦ã®å¤–éƒ¨å…¥åŠ›ã‚’ä¿¡é ¼ã›ãšæ¤œè¨¼

---

**ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 2: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®è¿½åŠ  (L67-L89)**

[... åŒæ§˜ã®è©³ç´°ãªè§£æ ...]
```

#### 3.4 å¤‰æ›´å†…å®¹ã®å…¨ä½“ã‚µãƒãƒª (What)

After detailed file analysis, create overall summary:

```markdown
å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:
1. **src/auth/middleware.js** (45è¡Œè¿½åŠ , 12è¡Œå‰Šé™¤)
   - ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼ã®å¤šå±¤é˜²å¾¡ã‚’å®Ÿè£…
   - ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ©Ÿèƒ½ã®è¿½åŠ 

2. **src/auth/validator.js** (23è¡Œè¿½åŠ , 5è¡Œå‰Šé™¤)
   - ã‚«ã‚¹ã‚¿ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒ¼ãƒˆè¿½åŠ 

3. **test/auth.test.js** (67è¡Œè¿½åŠ , 0è¡Œå‰Šé™¤)
   - åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è¿½åŠ 
   - ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š

ä¸»ãªæŠ€è¡“çš„å¤‰æ›´:
- å…¥åŠ›æ¤œè¨¼ã®å¼·åŒ–ï¼ˆé•·ã•ã€å‹ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆToken Bucketæ–¹å¼ï¼‰ã®å°å…¥
- ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ 45% â†’ 92%ã«å‘ä¸Š
```

#### 3.5 å½±éŸ¿ç¯„å›² (Impact)

Assess **impact** on the codebase with detailed dependency analysis:

```python
# Use Serena MCP to analyze symbol dependencies
impact_analysis = {
    "affected_modules": [],
    "breaking_changes": [],
    "api_compatibility": {},
    "performance_impact": {},
    "security_impact": {}
}

# For each changed file, find what depends on it
for file_info in files_analysis:
    # Use Serena's find_referencing_symbols to find dependencies
    if file is code file:
        symbols = serena_mcp.find_symbol(
            name_path="",  # Find all symbols in file
            relative_path=file_info["path"]
        )

        for symbol in symbols:
            references = serena_mcp.find_referencing_symbols(
                name_path=symbol["name_path"],
                relative_path=file_info["path"]
            )

            impact_analysis["affected_modules"].extend(references)

# Analyze breaking changes
for change in changed_sections:
    if is_api_change(change) and not_backward_compatible(change):
        impact_analysis["breaking_changes"].append({
            "file": change["file"],
            "change": change["description"],
            "migration": generate_migration_guide(change)
        })
```

**Example output**:

```markdown
### ğŸ—ï¸ å½±éŸ¿ç¯„å›²

#### å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

**ç›´æ¥çš„ãªå½±éŸ¿** (ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ç›´æ¥ä½¿ç”¨):
1. **api/routes/auth.js** (12ç®‡æ‰€ã§ä½¿ç”¨)
   - L45: `validateToken(req.headers.authorization)`
   - L67: `validateToken(sessionToken)`
   - å½±éŸ¿: æ–°ã—ã„æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯ãŒè‡ªå‹•é©ç”¨ã€ä¿®æ­£ä¸è¦

2. **api/routes/user.js** (8ç®‡æ‰€ã§ä½¿ç”¨)
   - L23: `middleware.validateToken(token)`
   - å½±éŸ¿: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„ãŒå¿…è¦ï¼ˆæ–°ã—ã„ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—å¯¾å¿œï¼‰

**é–“æ¥çš„ãªå½±éŸ¿** (ä¾å­˜é–¢ä¿‚ã‚’é€šã˜ã¦å½±éŸ¿):
1. **middleware/session.js**
   - auth/middlewareã‚’çµŒç”±ã—ã¦å½±éŸ¿
   - ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¤œè¨¼ãƒ•ãƒ­ãƒ¼ã«å¤‰æ›´ãªã—

2. **config/security.js**
   - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®è¨­å®šå€¤ã‚’å‚ç…§
   - æ–°ã—ã„è¨­å®šé …ç›®ã®è¿½åŠ ãŒå¿…è¦

#### ç ´å£Šçš„å¤‰æ›´ (Breaking Changes)

âŒ **ãªã—** - ã™ã¹ã¦ã®å¤‰æ›´ã¯å¾Œæ–¹äº’æ›æ€§ã‚’ä¿æŒ

#### APIäº’æ›æ€§

âœ… **å®Œå…¨äº’æ›** - æ—¢å­˜ã®APIã‚·ã‚°ãƒãƒãƒ£ã«å¤‰æ›´ãªã—

è¿½åŠ ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:
- `TokenFormatError` - ä¸æ­£ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- `TokenLengthError` - é•·ã•ãŒç¯„å›²å¤–
- `RateLimitError` - ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¶…é

ç§»è¡Œã‚¬ã‚¤ãƒ‰:
```javascript
// Before (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ - å¼•ãç¶šãå‹•ä½œ)
try {
  const user = validateToken(token);
} catch (err) {
  // ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼å‡¦ç†
}

// After (æ¨å¥¨ - æ–°ã—ã„ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã«å¯¾å¿œ)
try {
  const user = validateToken(token);
} catch (err) {
  if (err instanceof TokenFormatError) {
    // ä¸æ­£ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨ã®å‡¦ç†
  } else if (err instanceof RateLimitError) {
    // ãƒ¬ãƒ¼ãƒˆåˆ¶é™å°‚ç”¨ã®å‡¦ç†
  }
  // ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
}
```

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿

**æ¤œè¨¼å‡¦ç†**:
- è¿½åŠ ã®æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—: +0.5ms (L23-L44ã®å‡¦ç†)
- å…¨ä½“çš„ãªãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 2.3ms â†’ 2.8ms (+21%)
- ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•: ã‚ãšã‹ãªé…å»¶ vs ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¤§å¹…å‘ä¸Š

**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**:
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ‡ãƒ¼ã‚¿æ§‹é€ : +2MB (1ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ãŸã‚Š)
- Token Bucketãƒãƒƒãƒ—: O(active_users) ã®ãƒ¡ãƒ¢ãƒª

**ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**:
- âœ… å•é¡Œãªã—: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯Redisã¸ç§»è¡Œå¯èƒ½ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ï¼‰
- âš ï¸  æ³¨æ„: 10ä¸‡+ åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã¯RedisåŒ–ã‚’æ¨å¥¨

#### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å½±éŸ¿

**ä¿®æ­£ã•ã‚ŒãŸè„†å¼±æ€§**:
- **CVE-2024-1234** (Critical): Server crash via malformed tokens
- **CVSS Score**: 9.8 â†’ 0.0 (å®Œå…¨ä¿®æ­£)

**è¿½åŠ ã•ã‚ŒãŸã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½**:
1. å…¥åŠ›æ¤œè¨¼ã®å¤šå±¤é˜²å¾¡
2. DoSæ”»æ’ƒå¯¾ç­–ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
3. ç•°å¸¸æ¤œçŸ¥ã¨æ—©æœŸãƒªã‚¸ã‚§ã‚¯ãƒˆ

**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸**:
- Fuzzing testè¿½åŠ : 10,000ãƒ‘ã‚¿ãƒ¼ãƒ³
- ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹: å…¨ã¦ã‚«ãƒãƒ¼
```

#### 3.6 è¨­è¨ˆæ„å›³ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (Design)

Understand **design** decisions with deep architectural analysis:

```python
# Use Sequential Thinking to analyze design patterns
design_analysis = {
    "patterns": [],
    "trade_offs": [],
    "alternatives": [],
    "extensibility": [],
    "architectural_decisions": []
}

# Analyze each pattern used
for file_info in files_analysis:
    patterns = identify_design_patterns(file_info["content_after"])
    design_analysis["patterns"].extend(patterns)

# Analyze trade-offs
trade_offs = analyze_trade_offs(
    before=files_before,
    after=files_after,
    metrics=["performance", "security", "maintainability", "complexity"]
)
design_analysis["trade_offs"] = trade_offs
```

**Example output**:

```markdown
### ğŸ¨ è¨­è¨ˆæ„å›³ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

#### ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

**1. Chain of Responsibility (è²¬ä»»é€£é–ãƒ‘ã‚¿ãƒ¼ãƒ³)**

```
ãƒªã‚¯ã‚¨ã‚¹ãƒˆ â†’ å­˜åœ¨ãƒã‚§ãƒƒã‚¯ â†’ å‹ãƒã‚§ãƒƒã‚¯ â†’ é•·ã•ãƒã‚§ãƒƒã‚¯ â†’ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼ â†’ Base64æ¤œè¨¼ â†’ ç½²åæ¤œè¨¼ â†’ æˆåŠŸ
            â†“            â†“          â†“             â†“                â†“              â†“
           ã‚¨ãƒ©ãƒ¼       ã‚¨ãƒ©ãƒ¼      ã‚¨ãƒ©ãƒ¼         ã‚¨ãƒ©ãƒ¼           ã‚¨ãƒ©ãƒ¼         ã‚¨ãƒ©ãƒ¼
```

ãªãœã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³?
- å„æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—ãŒç‹¬ç«‹ã—ã¦å¤±æ•—å¯èƒ½
- æ–°ã—ã„æ¤œè¨¼ãƒ«ãƒ¼ãƒ«ã®è¿½åŠ ãŒå®¹æ˜“
- ãƒ†ã‚¹ãƒˆãŒæ›¸ãã‚„ã™ã„ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã‚’å€‹åˆ¥ã«ãƒ†ã‚¹ãƒˆï¼‰

**2. Fail Fast (æ—©æœŸå¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³)**

å®Ÿè£…ç®‡æ‰€: L23-L44ã®å„æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—

åˆ©ç‚¹:
- ãƒªã‚½ãƒ¼ã‚¹ã®ç„¡é§„ã‚’é˜²ãï¼ˆç„¡åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ—©æœŸã«ãƒªã‚¸ã‚§ã‚¯ãƒˆï¼‰
- ãƒ­ã‚°ã¨ã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ã®æ˜ç¢ºåŒ–
- ãƒ‡ãƒãƒƒã‚°ã®å®¹æ˜“ã•

**3. Defense in Depth (å¤šå±¤é˜²å¾¡)**

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ¤ãƒ¼:
```
Layer 1: å­˜åœ¨ãƒ»å‹ãƒã‚§ãƒƒã‚¯     â†’ åŸºæœ¬çš„ãªç„¡åŠ¹å…¥åŠ›ã‚’æ‹’å¦
Layer 2: é•·ã•ãƒã‚§ãƒƒã‚¯          â†’ DoSæ”»æ’ƒã‚’é˜²ã
Layer 3: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼      â†’ æ§‹é€ çš„ãªæ”»æ’ƒã‚’é˜²ã
Layer 4: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œè¨¼  â†’ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ”»æ’ƒã‚’é˜²ã
Layer 5: ç½²åæ¤œè¨¼              â†’ å½é€ ã‚’é˜²ã
Layer 6: ãƒ¬ãƒ¼ãƒˆåˆ¶é™            â†’ ç·å½“ãŸã‚Šæ”»æ’ƒã‚’é˜²ã
```

**4. Token Bucket (ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ )**

```javascript
// L67-L89: Token Bucketå®Ÿè£…
class TokenBucket {
  constructor(capacity, refillRate) {
    this.capacity = capacity;      // ãƒã‚±ãƒƒãƒˆã®å®¹é‡ï¼ˆæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰
    this.tokens = capacity;        // ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°
    this.refillRate = refillRate;  // ãƒˆãƒ¼ã‚¯ãƒ³ã®è£œå……ãƒ¬ãƒ¼ãƒˆï¼ˆæ¯ç§’ï¼‰
    this.lastRefill = Date.now();
  }

  tryConsume() {
    this.refill();  // ã¾ãšãƒˆãƒ¼ã‚¯ãƒ³ã‚’è£œå……
    if (this.tokens >= 1) {
      this.tokens -= 1;
      return true;  // ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨±å¯
    }
    return false;  // ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¶…é
  }

  refill() {
    const now = Date.now();
    const timePassed = (now - this.lastRefill) / 1000;
    const tokensToAdd = timePassed * this.refillRate;
    this.tokens = Math.min(this.capacity, this.tokens + tokensToAdd);
    this.lastRefill = now;
  }
}
```

ãªãœToken Bucket?
- **æŸ”è»Ÿæ€§**: ãƒãƒ¼ã‚¹ãƒˆçš„ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’è¨±å®¹
- **å…¬å¹³æ€§**: é•·æœŸçš„ã«ã¯å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¹³ç­‰
- **åŠ¹ç‡æ€§**: O(1)ã®æ™‚é–“è¨ˆç®—é‡

ä»£æ›¿æ¡ˆã¨ã®æ¯”è¼ƒ:
- Fixed Window: ãƒãƒ¼ã‚¹ãƒˆæ”»æ’ƒã«å¼±ã„ âŒ
- Sliding Window: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„ âŒ
- Token Bucket: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ âœ…

#### è¨­è¨ˆä¸Šã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

**1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**

æ±ºå®š: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’å„ªå…ˆ
- æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—è¿½åŠ ã«ã‚ˆã‚Š+0.5ms ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ 
- ã—ã‹ã—CVE-2024-1234 (Critical)ã‚’å®Œå…¨ä¿®æ­£
- **åˆ¤æ–­**: ã‚ãšã‹ãªé…å»¶ã¯è¨±å®¹ç¯„å›²ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯å¿…é ˆ

**2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**

æ±ºå®š: æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- åˆæœŸå®Ÿè£…: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªï¼ˆ+2MB/1ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰
- ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—æ™‚: Redisã¸ç§»è¡Œå¯èƒ½ï¼ˆã‚³ãƒ¼ãƒ‰ã«ã‚³ãƒ¡ãƒ³ãƒˆè¨˜è¼‰ï¼‰
- **åˆ¤æ–­**: æ—©æœŸæœ€é©åŒ–ã‚’é¿ã‘ã€å¿…è¦ã«ãªã£ã¦ã‹ã‚‰ç§»è¡Œ

**3. è¤‡é›‘æ€§ vs ä¿å®ˆæ€§**

è¿½åŠ ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰è¡Œæ•°: 68è¡Œ
- å„ã‚¹ãƒ†ãƒƒãƒ—ã«è©³ç´°ãªã‚³ãƒ¡ãƒ³ãƒˆ
- ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸92%
- **åˆ¤æ–­**: è¤‡é›‘ã•ã¯å¢—ã™ãŒã€ã‚³ãƒ¡ãƒ³ãƒˆã¨ãƒ†ã‚¹ãƒˆã§ä¿å®ˆæ€§ã‚’ç¢ºä¿

#### æ¤œè¨ã•ã‚ŒãŸä»£æ›¿æ¡ˆ

**ä»£æ›¿æ¡ˆ 1: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ (express-rate-limit)**

ãƒ¡ãƒªãƒƒãƒˆ:
- å®Ÿè£…ãŒç°¡å˜
- å®Ÿç¸¾ã‚ã‚Š

ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:
- ä¾å­˜é–¢ä¿‚ã®è¿½åŠ 
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºåˆ¶é™
- **å´ä¸‹ç†ç”±**: å­¦ç¿’ç›®çš„ã®ãŸã‚è‡ªå‰å®Ÿè£…ã‚’é¸æŠ

**ä»£æ›¿æ¡ˆ 2: ã‚ˆã‚Šå³æ ¼ãªæ¤œè¨¼ (å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹)**

ãƒ¡ãƒªãƒƒãƒˆ:
- ã•ã‚‰ã«è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ (+2ms)
- è¤‡é›‘æ€§å¢—å¤§
- **å´ä¸‹ç†ç”±**: ã‚³ã‚¹ãƒˆå¯¾åŠ¹æœãŒä½ã„

#### å°†æ¥ã®æ‹¡å¼µæ€§

**æ‹¡å¼µãƒã‚¤ãƒ³ãƒˆ 1: ã‚«ã‚¹ã‚¿ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚¿**

```javascript
// L45ã«è¿½åŠ å¯èƒ½ãªæ‹¡å¼µãƒã‚¤ãƒ³ãƒˆ
const customValidators = [];  // ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å¯èƒ½

function validateToken(token, customValidators = []) {
  // ... æ—¢å­˜ã®æ¤œè¨¼ ...

  // ã‚«ã‚¹ã‚¿ãƒ ãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿè¡Œ
  for (const validator of customValidators) {
    validator(token);
  }

  return jwt.verify(token, SECRET_KEY);
}
```

**æ‹¡å¼µãƒã‚¤ãƒ³ãƒˆ 2: Redisç§»è¡Œ**

```javascript
// L75: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒª â†’ Redis ã¸ã®ç§»è¡ŒãŒå®¹æ˜“
// ç¾åœ¨:
const rateLimiters = new Map();  // ãƒ¡ãƒ¢ãƒªå†…

// å°†æ¥:
const rateLimiters = new RedisTokenBucket(redisClient);
// ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¯åŒã˜ã¾ã¾
```

**æ‹¡å¼µãƒã‚¤ãƒ³ãƒˆ 3: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†**

```javascript
// å„æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é€ä¿¡å¯èƒ½
metrics.increment('auth.validation.format_check');
metrics.increment('auth.validation.rate_limit');
```

#### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã®æ±ºå®šäº‹é …

**1. åŒæœŸ vs éåŒæœŸå‡¦ç†**

æ±ºå®š: åŒæœŸå‡¦ç†ã‚’ç¶­æŒ
- ç†ç”±: æ¤œè¨¼ã¯é«˜é€Ÿï¼ˆ<1msï¼‰ã€éåŒæœŸåŒ–ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒç„¡é§„
- å°†æ¥: Redisç§»è¡Œæ™‚ã¯ async/await ã«å¤‰æ›´

**2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥**

æ±ºå®š: ä¾‹å¤–ãƒ™ãƒ¼ã‚¹ (throw Error)
- ç†ç”±: Expressã®ã‚¨ãƒ©ãƒ¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã¨ã®çµ±åˆ
- ä¸€è²«æ€§: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã¨ã®æ•´åˆæ€§

**3. è¨­å®šã®å¤–éƒ¨åŒ–**

æ±ºå®š: å®šæ•°ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¸
```javascript
// config/auth.js ã«ç§»å‹•
module.exports = {
  TOKEN_MIN_LENGTH: 50,
  TOKEN_MAX_LENGTH: 500,
  RATE_LIMIT_CAPACITY: 100,
  RATE_LIMIT_REFILL_RATE: 10
};
```

#### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Auth Middleware â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                             â”‚
    â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rate    â”‚                  â”‚ Token    â”‚
â”‚ Limiter â”‚                  â”‚Validator â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                            â”‚
     â”‚ OK                         â”‚
     â–¼                            â–¼
     â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚        â”‚ 1. å­˜åœ¨ãƒã‚§ãƒƒã‚¯     â”‚
     â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚        â”‚ 2. å‹ãƒã‚§ãƒƒã‚¯       â”‚
     â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚        â”‚ 3. é•·ã•ãƒã‚§ãƒƒã‚¯     â”‚
     â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚        â”‚ 4. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼ â”‚
     â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚        â”‚ 5. Base64æ¤œè¨¼     â”‚
     â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚        â”‚ 6. ç½²åæ¤œè¨¼        â”‚
     â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ ALL OK
                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Route Handlerâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
```

### Phase 4: Console Output

Display analysis in console:

```markdown
ğŸ“Š Commit Analysis: abc1234

## ğŸ¯ å¤‰æ›´ã®æ„å›³ (Why)
Fix security vulnerability in authentication middleware (CVE-2024-1234)

Related Issues:
- #1234: Security: Auth bypass in edge case
- #1235: Enhancement: Add rate limiting

## ğŸ“ å¤‰æ›´å†…å®¹ (What)

Changed Files (3):
- src/auth/middleware.js (+45, -12)
- src/auth/validator.js (+23, -5)
- test/auth.test.js (+67, -0)

Key Changes:
- Add input validation for auth tokens
- Implement rate limiting (100 req/min)
- Add comprehensive test coverage

## ğŸ—ï¸ å½±éŸ¿ç¯„å›² (Impact)

Affected Modules:
- api/routes/* (10 files) - All routes using auth
- middleware/session.js - Session handling logic
- config/security.js - Security configuration

Risk Assessment:
âœ… No breaking changes
âœ… Backward compatible
âš ï¸  Requires config update in production

## ğŸ¨ è¨­è¨ˆæ„å›³ (Design)

Pattern: Chain of Responsibility for validation
Trade-off: +2MB memory for 10x security improvement
Extensibility: Can add custom validators via plugin

## ğŸ”— ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

Before this commit:
- abc0123: Refactor auth module structure
- abc0122: Add auth logging

After this commit:
- abc1235: Update documentation
- abc1236: Deploy to staging

Related PR: #5234 "Security hardening"
- 5 approving reviews
- Passed all CI checks
- Merged 2 days ago

---

ğŸ’¾ Exporting to Notion...
```

### Phase 5: Notion Export with Deep Analysis (use Notion MCP)

**IMPORTANT**: Export ALL detailed analysis including line-by-line code explanations.

#### 5.1 Find OSS Page

```python
# Query OSSãƒªã‚¹ãƒˆ database
oss_pages = notion_mcp.query_database(
    database_id=oss_database_id,
    filter={"property": "GitHub URL", "url": {"equals": repo_url}}
)

if not oss_pages:
    print("âš ï¸  Repository not registered. Run: /register-oss <url>")
    return

oss_page_id = oss_pages[0]["id"]
```

#### 5.2 Get Commits Database ID from Memory

```python
# Get OSS-specific commits database ID from current_oss memory
current_oss = serena_mcp.read_memory("current_oss")
commits_database_id = current_oss["commits_database_id"]
```

**Important**: Each OSS has its own Commits & PRs database. The database ID is stored in Serena memory when the OSS is registered.

#### 5.3 Create Commit Entry with Deep Analysis Content

```python
# Build detailed content blocks with ALL analysis sections
content_blocks = []

# 1. å¤‰æ›´ã®æ„å›³ (Why) - Heading 2
content_blocks.append({
    "heading_2": {"rich_text": [{"text": {"content": "ğŸ¯ å¤‰æ›´ã®æ„å›³ (Why)"}}]}
})
content_blocks.append({
    "paragraph": {"rich_text": [{"text": {"content": why_analysis_text}}]}
})

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®è©³ç´°è§£æ - For EACH file
for file_analysis in files_analysis:
    # File heading
    content_blocks.append({
        "heading_2": {"rich_text": [{"text": {"content": f"ğŸ“„ {file_analysis['path']}"}}]}
    })

    # File role
    content_blocks.append({
        "heading_3": {"rich_text": [{"text": {"content": "ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²"}}]}
    })
    content_blocks.append({
        "paragraph": {"rich_text": [{"text": {"content": file_analysis["file_role"]}}]}
    })

    # Change summary
    content_blocks.append({
        "heading_3": {"rich_text": [{"text": {"content": "å¤‰æ›´ã®æ¦‚è¦"}}]}
    })
    content_blocks.append({
        "paragraph": {"rich_text": [{"text": {"content": file_analysis["change_summary"]}}]}
    })

    # Detailed code walkthrough (LINE-BY-LINE)
    content_blocks.append({
        "heading_3": {"rich_text": [{"text": {"content": "ğŸ” è©³ç´°ãªå¤‰æ›´è§£æ"}}]}
    })

    for section in file_analysis["code_walkthrough"]:
        # Section heading
        content_blocks.append({
            "heading_4": {"rich_text": [{"text": {
                "content": f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³: {section['line_range']} - {section['change_type']}"
            }}]}
        })

        # Code before (if exists)
        if section["code_before"]:
            content_blocks.append({
                "paragraph": {"rich_text": [{"text": {"content": "**å¤‰æ›´å‰ã®ã‚³ãƒ¼ãƒ‰:**"}}]}
            })
            content_blocks.append({
                "code": {
                    "rich_text": [{"text": {"content": section["code_before"]}}],
                    "language": detect_language(file_analysis["path"])
                }
            })

        # Code after
        content_blocks.append({
            "paragraph": {"rich_text": [{"text": {"content": "**å¤‰æ›´å¾Œã®ã‚³ãƒ¼ãƒ‰:**"}}]}
        })
        content_blocks.append({
            "code": {
                "rich_text": [{"text": {"content": section["code_after"]}}],
                "language": detect_language(file_analysis["path"])
            }
        })

        # Detailed explanation (LINE-BY-LINE)
        content_blocks.append({
            "paragraph": {"rich_text": [{"text": {"content": "**è©³ç´°ãªè§£èª¬:**"}}]}
        })
        content_blocks.append({
            "paragraph": {"rich_text": [{"text": {"content": section["explanation"]}}]}
        })

        # Pattern used
        if section.get("patterns"):
            content_blocks.append({
                "paragraph": {"rich_text": [{"text": {"content": f"**ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³:** {section['patterns']}"}}]}
            })

# 3. å½±éŸ¿ç¯„å›² (Impact)
content_blocks.append({
    "heading_2": {"rich_text": [{"text": {"content": "ğŸ—ï¸ å½±éŸ¿ç¯„å›² (Impact)"}}]}
})
content_blocks.extend(create_impact_blocks(impact_analysis))

# 4. è¨­è¨ˆæ„å›³ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (Design)
content_blocks.append({
    "heading_2": {"rich_text": [{"text": {"content": "ğŸ¨ è¨­è¨ˆæ„å›³ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£"}}]}
})
content_blocks.extend(create_design_blocks(design_analysis))

# 5. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ (Context)
content_blocks.append({
    "heading_2": {"rich_text": [{"text": {"content": "ğŸ”— ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"}}]}
})
content_blocks.extend(create_context_blocks(related_commits, related_issues, related_pr))

# 6. Full Diff (in toggle for reference)
content_blocks.append({
    "toggle": {
        "rich_text": [{"text": {"content": "ğŸ“‹ å®Œå…¨ãªDiff (å‚è€ƒ)"}}],
        "children": create_diff_blocks(commit_data["files"])
    }
})

# Create page in OSS-specific Commits & PRs database
commit_page = notion_mcp.create_page(
    parent={"database_id": commits_database_id},
    properties={
        "Title": f"{commit_hash_short}: {commit_message_first_line}",
        "Type": "Commit",  # NEW: Distinguish from PRs
        "Commit ID / PR No": commit_hash,
        "Comment": commit_message,
        "GitHub URL": f"{repo_url}/commit/{commit_hash}",
        "Analyzed Date": {"start": datetime.now().isoformat()},  # NEW
        "Memo": "",  # Empty for user to fill
    },
    children=content_blocks  # ALL detailed analysis
)

print(f"âœ… Exported {len(content_blocks)} content blocks to Notion")
```

**Note**:
- Each file gets its own detailed section
- Code is shown with syntax highlighting
- Line-by-line explanations are included
- Full diff is in a toggle block for reference

#### 5.4 Confirm Export

```markdown
âœ… Exported to Notion!

ğŸ“„ Notion Page: https://notion.so/commit-page-id
ğŸ”— View commit: [link to OSS page] â†’ [link to this commit]

ğŸ’¡ Tip: Add personal notes in the "Memo" field
```

### Phase 6: Cleanup and Restore

**IMPORTANT**: Return repository to original state after analysis.

```python
# Restore original branch
try:
    subprocess.run(
        ["git", "checkout", cleanup_info["original_branch"]],
        cwd=cleanup_info["repo_path"],
        check=True,
        capture_output=True
    )
    print(f"âœ… Restored to branch: {cleanup_info['original_branch']}")

except subprocess.CalledProcessError as e:
    print(f"âš ï¸  Could not restore branch: {e}")
    print(f"   Please manually run: cd {cleanup_info['repo_path']} && git checkout {cleanup_info['original_branch']}")

# Deactivate Serena project
try:
    serena_mcp.think_about_whether_you_are_done()
    print(f"âœ… Serena MCP analysis complete")
except:
    pass
```

### Phase 7: Next Commit Suggestions

After successful analysis, suggest next commits to analyze:

```python
# Get surrounding commits for context
timeline_commits = github_mcp.list_commits(
    owner=owner,
    repo=repo,
    per_page=5
)

# Filter out already analyzed commits
analyzed_commits = serena_mcp.read_memory("analyzed_commits") or []
unanalyzed = [c for c in timeline_commits if c["sha"] not in analyzed_commits]

# Mark current commit as analyzed
analyzed_commits.append(commit_hash)
serena_mcp.write_memory("analyzed_commits", analyzed_commits)
```

Display suggestions:

```markdown
---

ğŸ” Next Suggestions

Recent commits from this project:

1. ğŸ†• def5678 - Add rate limiting to API endpoints
   ğŸ“… 2025-01-14 â€¢ ğŸ‘¤ janedoe â€¢ âœï¸ 5 files
   /analyze-commit def5678

2. ğŸ†• ghi9012 - Update dependencies
   ğŸ“… 2025-01-13 â€¢ ğŸ‘¤ maintainer â€¢ âœï¸ 1 file
   /analyze-commit ghi9012

3. âœ… xyz3456 - Refactor auth module (already analyzed)

ğŸ’¡ Commands:
  /list-commits           # Browse all recent commits
  /list-prs              # Browse pull requests
  /current-oss           # Check current project

Continue your learning journey! ğŸš€
```

## Error Handling

### Repository Not Set

```
âš ï¸  No Repository Specified

You haven't specified a repository URL and no current project is set.

Options:
1. Register a project first:
   /register-oss https://github.com/expressjs/express
   /analyze-commit abc1234

2. Or specify URL directly:
   /analyze-commit https://github.com/expressjs/express abc1234

Check current project:
   /current-oss
```

### Commit Not Found

```
âŒ Error: Commit not found

Commit: abc1234
Repository: expressjs/express

Possible reasons:
- Commit hash is incorrect
- Commit was force-pushed/deleted
- Private repository without access

Please verify the commit hash.
```

### Repository Not Registered

```
âš ï¸  Repository Not Registered

Before analyzing commits, register the repository:

  /register-oss https://github.com/expressjs/express

This creates a parent entry in your OSSãƒªã‚¹ãƒˆ database.
```

### Large Diff

```
âš ï¸  Large Commit Detected

This commit changes 150+ files (12,000 lines).

Options:
1. Continue with full analysis (~5min)
2. Summary only (skip detailed analysis)
3. Cancel

> _
```

### Related Issue Not Found

```
â„¹ï¸  Context Gathering

Found issue references: #1234, #5678

âœ… #1234: Security vulnerability (loaded)
âŒ #5678: Issue not found or private

Continuing with available context...
```

## Output Format

### Console (always shown)

```markdown
ğŸ“Š Commit Analysis Complete

## Summary
- Changed: 3 files
- Added: 135 lines
- Removed: 17 lines
- Impact: Medium (10 dependent modules)

## Key Insights
ğŸ¯ Why: Security fix for CVE-2024-1234
ğŸ“ What: Auth middleware validation
ğŸ—ï¸ Impact: All API routes (backward compatible)
ğŸ¨ Design: Chain of Responsibility pattern

ğŸ”— Full analysis: https://notion.so/commit-page-id
```

### Notion (complete analysis)

Full detailed page with:
- ğŸ¯ å¤‰æ›´ã®æ„å›³
- ğŸ“ å¤‰æ›´å†…å®¹ (with code diff)
- ğŸ—ï¸ å½±éŸ¿ç¯„å›²
- ğŸ¨ è¨­è¨ˆæ„å›³
- ğŸ”— ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ (issues, commits, PR)
- ğŸ“‹ Complete diff (in toggle)

## Advanced Features

### Compare Mode

```
/analyze-commit <url> <commit1>..<commit2>
```

Analyze changes between two commits.

### Focus Analysis

```
/analyze-commit <url> <commit> --focus security
```

Focus on specific aspects:
- `security`: Security implications
- `performance`: Performance impact
- `api`: API changes
- `breaking`: Breaking changes

### Skip Export

```
/analyze-commit <url> <commit> --no-export
```

Analyze only, don't export to Notion.

## Tips

1. **Start with context**: Always check related issues first
2. **Think in layers**: Why â†’ What â†’ Impact â†’ Design
3. **Use your notes**: Fill the "Memo" field in Notion
4. **Compare commits**: Use before/after commits for better understanding
5. **Focus on intent**: Understand why, not just what changed
